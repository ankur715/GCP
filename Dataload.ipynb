{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6236555a",
   "metadata": {},
   "source": [
    "This program will load the data needed for the analysis and reporting of the insights.\n",
    "\n",
    "- [Import modules](#1)\n",
    "- [Load zipped files](#2)\n",
    "- [Load customers and transactions](#3)\n",
    "- [Join tables](#4)\n",
    "- [Save loaded tables](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd46b08",
   "metadata": {},
   "source": [
    "### <a id=\"1\"></a>Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec51add6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules for the defined functions needed\n",
    "\n",
    "# Load files from the system \n",
    "import zipfile, fnmatch, os\n",
    "# Data reading and manipulation\n",
    "import pandas as pd\n",
    "# Defined functions in the functions.py script\n",
    "import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d3a3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory for the project (under LS Direct folder)\n",
    "mainDir = \"../LS Direct/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052bcc39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Archives',\n",
       " 'Dataload_AP.ipynb',\n",
       " 'EDA_AP.ipynb',\n",
       " 'functions.py',\n",
       " 'Loaded_Tables',\n",
       " 'LS\\xa0Direct\\xa0- Technical Assessment - Ankur Patel.pptx',\n",
       " 'Technical_Data.zip',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of files in mainDir\n",
    "os.listdir(mainDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d810016",
   "metadata": {},
   "source": [
    "### <a id=\"2\"></a>Load zipped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c901e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the zip file in read mode and extract it in the same path\n",
    "Technical_Data_Path = mainDir + \"Technical_Data.zip\"\n",
    "with zipfile.ZipFile(Technical_Data_Path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6240e6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../LS Direct/Test_Data/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Folder with the payload data \n",
    "Test_Data_Path = mainDir + \"Test_Data/\"\n",
    "Test_Data_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c52319e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each files in the path, filter to .zip, and extract it to the current working directory\n",
    "pattern = '*.zip'\n",
    "for root, dirs, files in os.walk(Test_Data_Path):\n",
    "    for filename in fnmatch.filter(files, pattern):\n",
    "#         print(os.path.join(root, filename))\n",
    "        zipfile.ZipFile(os.path.join(root, filename)).extractall(os.path.join(root, os.path.splitext(filename)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4a7b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Payload periods\n",
    "payload = os.listdir(Test_Data_Path)\n",
    "len(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6adb3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the zip extensions\n",
    "payload_unzip = [x for x in payload if \"zip\" not in x]\n",
    "# Zip extensions\n",
    "payload_zip = [x for x in payload if \"zip\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97fbba03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unzipped payload folders\n",
    "len(payload_unzip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab965df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['payload_2022-01-01_to_2022-01-07.csv',\n",
       " 'payload_2022-01-08_to_2022-01-14.csv',\n",
       " 'payload_2022-01-15_to_2022-01-21.csv',\n",
       " 'payload_2022-01-22_to_2022-01-28.csv',\n",
       " 'payload_2022-01-29_to_2022-02-04.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the list in ascending order for the earliest 5 time periods\n",
    "sorted(payload_unzip)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef76160a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['payload_2023-10-28_to_2023-11-03.csv',\n",
       " 'payload_2023-10-21_to_2023-10-27.csv',\n",
       " 'payload_2023-10-14_to_2023-10-20.csv',\n",
       " 'payload_2023-10-07_to_2023-10-13.csv',\n",
       " 'payload_2023-09-30_to_2023-10-06.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort the list in descending order for the latest 5 time periods\n",
    "sorted(payload_unzip, reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd8a01",
   "metadata": {},
   "source": [
    "- Side note: zipped files save disk space and are easier to transfer. It could be decided to remove the zipped files once the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2131728e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>payload_2022-01-01_to_2022-01-07.csv</td>\n",
       "      <td>customers_2022-01-01_to_2022-01-07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>payload_2022-01-01_to_2022-01-07.csv</td>\n",
       "      <td>transactions_2022-01-01_to_2022-01-07.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>payload_2022-01-08_to_2022-01-14.csv</td>\n",
       "      <td>customers_2022-01-08_to_2022-01-14.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>payload_2022-01-08_to_2022-01-14.csv</td>\n",
       "      <td>transactions_2022-01-08_to_2022-01-14.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>payload_2022-01-15_to_2022-01-21.csv</td>\n",
       "      <td>customers_2022-01-15_to_2022-01-21.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Folder  \\\n",
       "0  payload_2022-01-01_to_2022-01-07.csv   \n",
       "1  payload_2022-01-01_to_2022-01-07.csv   \n",
       "2  payload_2022-01-08_to_2022-01-14.csv   \n",
       "3  payload_2022-01-08_to_2022-01-14.csv   \n",
       "4  payload_2022-01-15_to_2022-01-21.csv   \n",
       "\n",
       "                                        File  \n",
       "0     customers_2022-01-01_to_2022-01-07.csv  \n",
       "1  transactions_2022-01-01_to_2022-01-07.csv  \n",
       "2     customers_2022-01-08_to_2022-01-14.csv  \n",
       "3  transactions_2022-01-08_to_2022-01-14.csv  \n",
       "4     customers_2022-01-15_to_2022-01-21.csv  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store directories and filenames into a table\n",
    "payload_dir = []\n",
    "for folder in sorted(payload_unzip):\n",
    "    payload_period_files = os.listdir(Test_Data_Path + folder)\n",
    "    for file in sorted(payload_period_files):\n",
    "        payload_dir.append((folder, file))\n",
    "\n",
    "payload_files = pd.DataFrame(payload_dir, columns=['Folder', 'File'])\n",
    "payload_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0854b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filpath for the files\n",
    "payload_files[\"Filepath\"] = Test_Data_Path + payload_files[\"Folder\"] + \"/\" + payload_files[\"File\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57db2d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>Filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>payload_2023-10-14_to_2023-10-20.csv</td>\n",
       "      <td>transactions_2023-10-14_to_2023-10-20.csv</td>\n",
       "      <td>../LS Direct/Test_Data/payload_2023-10-14_to_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>payload_2023-10-21_to_2023-10-27.csv</td>\n",
       "      <td>customers_2023-10-21_to_2023-10-27.csv</td>\n",
       "      <td>../LS Direct/Test_Data/payload_2023-10-21_to_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>payload_2023-10-21_to_2023-10-27.csv</td>\n",
       "      <td>transactions_2023-10-21_to_2023-10-27.csv</td>\n",
       "      <td>../LS Direct/Test_Data/payload_2023-10-21_to_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>payload_2023-10-28_to_2023-11-03.csv</td>\n",
       "      <td>customers_2023-10-28_to_2023-11-03.csv</td>\n",
       "      <td>../LS Direct/Test_Data/payload_2023-10-28_to_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>payload_2023-10-28_to_2023-11-03.csv</td>\n",
       "      <td>transactions_2023-10-28_to_2023-11-03.csv</td>\n",
       "      <td>../LS Direct/Test_Data/payload_2023-10-28_to_2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Folder  \\\n",
       "187  payload_2023-10-14_to_2023-10-20.csv   \n",
       "188  payload_2023-10-21_to_2023-10-27.csv   \n",
       "189  payload_2023-10-21_to_2023-10-27.csv   \n",
       "190  payload_2023-10-28_to_2023-11-03.csv   \n",
       "191  payload_2023-10-28_to_2023-11-03.csv   \n",
       "\n",
       "                                          File  \\\n",
       "187  transactions_2023-10-14_to_2023-10-20.csv   \n",
       "188     customers_2023-10-21_to_2023-10-27.csv   \n",
       "189  transactions_2023-10-21_to_2023-10-27.csv   \n",
       "190     customers_2023-10-28_to_2023-11-03.csv   \n",
       "191  transactions_2023-10-28_to_2023-11-03.csv   \n",
       "\n",
       "                                              Filepath  \n",
       "187  ../LS Direct/Test_Data/payload_2023-10-14_to_2...  \n",
       "188  ../LS Direct/Test_Data/payload_2023-10-21_to_2...  \n",
       "189  ../LS Direct/Test_Data/payload_2023-10-21_to_2...  \n",
       "190  ../LS Direct/Test_Data/payload_2023-10-28_to_2...  \n",
       "191  ../LS Direct/Test_Data/payload_2023-10-28_to_2...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payload_files.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e358eef",
   "metadata": {},
   "source": [
    "### <a id=\"3\"></a>Load customers and transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd242ee3",
   "metadata": {},
   "source": [
    "#### _Customers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70b722fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to customers' files\n",
    "payload_customers_path = payload_files[payload_files[\"File\"].str.contains(\"customers\")]\n",
    "# reset index to prevent errors in for loops, and remove the unnecessary index column\n",
    "payload_customers_path = payload_customers_path.reset_index().drop(\"index\", axis=1)\n",
    "payload_customers_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1065513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of 96 Customers tables\n",
      "Errors in 0 tables\n"
     ]
    }
   ],
   "source": [
    "# Reading each customers csv and appending to a list\n",
    "# Also check if data size error (in case of inconsistent tables during different payload periods)\n",
    "Customers_tables = []\n",
    "customers_error_cnt = 0\n",
    "customers_error_files = []\n",
    "customers_columns = [\"Customer_ID\",\"First Name\",\"Last Name\",\"Address\",\"City\",\"State_Abbr\",\"Zip\",\"Start_Date\"]\n",
    "for i in range(len(payload_customers_path)):\n",
    "    Customers = pd.read_csv(payload_customers_path[\"Filepath\"][i])\n",
    "    # Checks if all tables have the same column (works in this example since they are same, but the shape would error otherwise)\n",
    "    if all(Customers.columns == customers_columns):\n",
    "        Customers_tables.append(Customers)\n",
    "    else:\n",
    "        customers_error_cnt += 1\n",
    "        customers_error_files.append(payload_customers_path[\"Filepath\"][i])\n",
    "        print(\"Error: Inconsistent data size. Please check the following file:\")\n",
    "        print(payload_customers_path[\"Filepath\"][i])\n",
    "print(\"\\nList of {} Customers tables\".format(len(Customers_tables)))\n",
    "print(\"Errors in {} tables\".format(customers_error_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cced0ae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161006, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the list of customers ta tables into a single dataframe\n",
    "Customers = pd.concat(Customers_tables)\n",
    "Customers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a55fa8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State_Abbr</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Start_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C84725947570</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Jones</td>\n",
       "      <td>947 James Greens</td>\n",
       "      <td>Scottland</td>\n",
       "      <td>PR</td>\n",
       "      <td>603.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C97761921457</td>\n",
       "      <td>Taylor</td>\n",
       "      <td>Bennett</td>\n",
       "      <td>2980 Salas Springs Apt. 814</td>\n",
       "      <td>Sanchezbury</td>\n",
       "      <td>NE</td>\n",
       "      <td>68040.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C85509443959</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>Crawford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C77919217553</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>72595 Tamara Circle Apt. 394</td>\n",
       "      <td>Robertfurt</td>\n",
       "      <td>NE</td>\n",
       "      <td>68094.0</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C94654194089</td>\n",
       "      <td>Stacy</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>C57654725789</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Rivera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>C98296500535</td>\n",
       "      <td>Catherine</td>\n",
       "      <td>Hill</td>\n",
       "      <td>176 John Mountain</td>\n",
       "      <td>Victoriahaven</td>\n",
       "      <td>OK</td>\n",
       "      <td>73017.0</td>\n",
       "      <td>2023-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>C46169950639</td>\n",
       "      <td>Eric</td>\n",
       "      <td>Reed</td>\n",
       "      <td>702 Schaefer Parkways Suite 621</td>\n",
       "      <td>Lake Robert</td>\n",
       "      <td>OK</td>\n",
       "      <td>73018.0</td>\n",
       "      <td>2023-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>C70529012461</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Farley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>C87041346000</td>\n",
       "      <td>James</td>\n",
       "      <td>Hill</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161006 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Customer_ID First Name Last Name                          Address  \\\n",
       "0    C84725947570  Elizabeth     Jones                 947 James Greens   \n",
       "1    C97761921457     Taylor   Bennett      2980 Salas Springs Apt. 814   \n",
       "2    C85509443959     Amanda  Crawford                              NaN   \n",
       "3    C77919217553    Melissa  Martinez     72595 Tamara Circle Apt. 394   \n",
       "4    C94654194089      Stacy   Sanders                              NaN   \n",
       "..            ...        ...       ...                              ...   \n",
       "731  C57654725789       Mark    Rivera                              NaN   \n",
       "732  C98296500535  Catherine      Hill                176 John Mountain   \n",
       "733  C46169950639       Eric      Reed  702 Schaefer Parkways Suite 621   \n",
       "734  C70529012461       Tara    Farley                              NaN   \n",
       "735  C87041346000      James      Hill                              NaN   \n",
       "\n",
       "              City State_Abbr      Zip  Start_Date  \n",
       "0        Scottland         PR    603.0  2022-01-01  \n",
       "1      Sanchezbury         NE  68040.0  2022-01-01  \n",
       "2              NaN        NaN      NaN  2022-01-01  \n",
       "3       Robertfurt         NE  68094.0  2022-01-01  \n",
       "4              NaN        NaN      NaN  2022-01-01  \n",
       "..             ...        ...      ...         ...  \n",
       "731            NaN        NaN      NaN  2023-10-30  \n",
       "732  Victoriahaven         OK  73017.0  2023-10-30  \n",
       "733    Lake Robert         OK  73018.0  2023-10-30  \n",
       "734            NaN        NaN      NaN  2023-10-30  \n",
       "735            NaN        NaN      NaN  2023-10-30  \n",
       "\n",
       "[161006 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20438dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State_Abbr</th>\n",
       "      <th>Zip</th>\n",
       "      <th>Start_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Customer_ID, First Name, Last Name, Address, City, State_Abbr, Zip, Start_Date]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicated rows\n",
    "Customers[Customers.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89d0db69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161006, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates (if there were any duplicates)\n",
    "Customers = Customers.drop_duplicates()\n",
    "Customers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "748df669",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 161006 entries, 0 to 735\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   Customer_ID  161006 non-null  object \n",
      " 1   First Name   161006 non-null  object \n",
      " 2   Last Name    161006 non-null  object \n",
      " 3   Address      122727 non-null  object \n",
      " 4   City         122727 non-null  object \n",
      " 5   State_Abbr   122727 non-null  object \n",
      " 6   Zip          122727 non-null  float64\n",
      " 7   Start_Date   161006 non-null  object \n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Data type of Customers columns\n",
    "Customers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7652e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer_ID        0\n",
       "First Name         0\n",
       "Last Name          0\n",
       "Address        38279\n",
       "City           38279\n",
       "State_Abbr     38279\n",
       "Zip            38279\n",
       "Start_Date         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values\n",
    "Customers.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9619aa7",
   "metadata": {},
   "source": [
    "Checking the loaded Customers table, the customer's ID, first name, last name, and start date are not missing; however, around 23% of the customer addresses are missing. The loading also checked for consistent data size, columns, and printed error message otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949d195b",
   "metadata": {},
   "source": [
    "#### _Transactions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df751142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to transactions' files\n",
    "payload_transactions_path = payload_files[payload_files[\"File\"].str.contains(\"transactions\")]\n",
    "# reset index to prevent errors in for loops, and remove the unnecessary index column\n",
    "payload_transactions_path = payload_transactions_path.reset_index().drop(\"index\", axis=1)\n",
    "payload_transactions_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1de999d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-01-21_to_2023-01-27.csv/transactions_2023-01-21_to_2023-01-27.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-01-28_to_2023-02-03.csv/transactions_2023-01-28_to_2023-02-03.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-03-25_to_2023-03-31.csv/transactions_2023-03-25_to_2023-03-31.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-04-22_to_2023-04-28.csv/transactions_2023-04-22_to_2023-04-28.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-05-13_to_2023-05-19.csv/transactions_2023-05-13_to_2023-05-19.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-06-24_to_2023-06-30.csv/transactions_2023-06-24_to_2023-06-30.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-08-12_to_2023-08-18.csv/transactions_2023-08-12_to_2023-08-18.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-08-19_to_2023-08-25.csv/transactions_2023-08-19_to_2023-08-25.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-09-02_to_2023-09-08.csv/transactions_2023-09-02_to_2023-09-08.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-09-16_to_2023-09-22.csv/transactions_2023-09-16_to_2023-09-22.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-09-30_to_2023-10-06.csv/transactions_2023-09-30_to_2023-10-06.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-10-14_to_2023-10-20.csv/transactions_2023-10-14_to_2023-10-20.csv\n",
      "Error: Please check the following file:\n",
      "../LS Direct/Test_Data/payload_2023-10-28_to_2023-11-03.csv/transactions_2023-10-28_to_2023-11-03.csv\n",
      "\n",
      "List of 83 Transactions tables\n",
      "Errors in 13 tables\n"
     ]
    }
   ],
   "source": [
    "# Reading each transactions csv and appending to a list\n",
    "# Also check if data size error (in case of inconsistent tables during different payload periods)\n",
    "Transactions_tables = []\n",
    "transactions_error_cnt = 0\n",
    "transactions_error_files = []\n",
    "for i in range(len(payload_transactions_path)):\n",
    "    Transactions = pd.read_csv(payload_transactions_path[\"Filepath\"][i])\n",
    "    # check if there are 8 columns as expected (in case of inconsistent tables during different payload periods)\n",
    "    if Transactions.shape[1] == 8:\n",
    "        Transactions_tables.append(Transactions)\n",
    "    else:\n",
    "        transactions_error_cnt += 1\n",
    "        transactions_error_files.append(payload_transactions_path[\"Filepath\"][i])\n",
    "        print(\"Error: Please check the following file:\")\n",
    "        print(payload_transactions_path[\"Filepath\"][i])\n",
    "print(\"\\nList of {} Transactions tables\".format(len(Transactions_tables)))\n",
    "print(\"Errors in {} tables\".format(transactions_error_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "072e2011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7079, 9)\n",
      "(7184, 9)\n",
      "(6696, 9)\n",
      "(6832, 9)\n",
      "(6945, 9)\n",
      "(6519, 9)\n",
      "(7449, 9)\n",
      "(4862, 9)\n",
      "(4175, 9)\n",
      "(4602, 9)\n",
      "(4080, 9)\n",
      "(3919, 9)\n",
      "(1894, 10)\n"
     ]
    }
   ],
   "source": [
    "# checking the size shows that it included 1-2 unnecessary index columns\n",
    "for i in range(13):\n",
    "    # error file included index\n",
    "    Transactions = pd.read_csv(transactions_error_files[i])\n",
    "    print(Transactions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c383501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Transaction_ID</th>\n",
       "      <th>Customer_ID</th>\n",
       "      <th>Department</th>\n",
       "      <th>Category</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>532685089571</td>\n",
       "      <td>C54783873038</td>\n",
       "      <td>Men</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Crew Neck Shirt</td>\n",
       "      <td>22.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>48243694426</td>\n",
       "      <td>C52820349964</td>\n",
       "      <td>Men</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Corduroy Pants</td>\n",
       "      <td>38.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>48243694426</td>\n",
       "      <td>C52820349964</td>\n",
       "      <td>Men</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Chinos</td>\n",
       "      <td>39.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>48243694426</td>\n",
       "      <td>C52820349964</td>\n",
       "      <td>Men</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Flannel Shirt</td>\n",
       "      <td>35.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-10-28</td>\n",
       "      <td>29702850787</td>\n",
       "      <td>C86240445650</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Tunic</td>\n",
       "      <td>29.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        Date  Transaction_ID   Customer_ID  \\\n",
       "0             0           1  2023-10-28    532685089571  C54783873038   \n",
       "1             1           2  2023-10-28     48243694426  C52820349964   \n",
       "2             2           3  2023-10-28     48243694426  C52820349964   \n",
       "3             3           5  2023-10-28     48243694426  C52820349964   \n",
       "4             4           6  2023-10-28     29702850787  C86240445650   \n",
       "\n",
       "  Department Category              SKU  Price  Discount  \n",
       "0        Men   Shirts  Crew Neck Shirt  22.77       NaN  \n",
       "1        Men  Bottoms   Corduroy Pants  38.77       NaN  \n",
       "2        Men  Bottoms           Chinos  39.77       NaN  \n",
       "3        Men   Shirts    Flannel Shirt  35.77       NaN  \n",
       "4      Women     Tops            Tunic  29.77       NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transactions = pd.read_csv(transactions_error_files[12])\n",
    "Transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a081b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 96 Transactions tables\n"
     ]
    }
   ],
   "source": [
    "# Below is the modification to the loading error that occured due to the columns inconsistency\n",
    "# Select the useful columns from the loaded table to remove the index columns\n",
    "transactions_columns = [\"Date\",\"Transaction_ID\",\"Customer_ID\",\"Department\",\"Category\",\"SKU\",\"Price\",\"Discount\"]\n",
    "Transactions_tables = []\n",
    "for i in range(len(payload_transactions_path)):\n",
    "    Transactions = pd.read_csv(payload_transactions_path[\"Filepath\"][i])\n",
    "    Transactions = Transactions[transactions_columns]\n",
    "    Transactions_tables.append(Transactions)\n",
    "print(\"List of {} Transactions tables\".format(len(Transactions_tables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "52a10841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(655605, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the list of transactions ta tables into a single dataframe\n",
    "Transactions = pd.concat(Transactions_tables)\n",
    "Transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1accc195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183705, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicated rows\n",
    "Transactions[Transactions.duplicated(keep=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77959156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559233, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates (~90000 rows)\n",
    "Transactions = Transactions.drop_duplicates()\n",
    "Transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f690f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                   0\n",
       "Transaction_ID         0\n",
       "Customer_ID            0\n",
       "Department             0\n",
       "Category               0\n",
       "SKU                    0\n",
       "Price                  0\n",
       "Discount          535621\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Null values\n",
    "Transactions.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4898fb",
   "metadata": {},
   "source": [
    "The loaded Transactions table didn't include any missing values for all the columns except for Discount, which included over 95% of missing values. The loading also checked for consistent data size, columns, and printed error message otherwise. There were 13 tables that included index columns which were excluded before merging the tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "385d2c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226e42a",
   "metadata": {},
   "source": [
    "### <a id=\"4\"></a>Join tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f22066c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536885, 15)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Customer_Transactions = pd.merge(Customers, Transactions, on=\"Customer_ID\")\n",
    "Customer_Transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb784d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 536885 entries, 0 to 536884\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   Customer_ID     536885 non-null  object \n",
      " 1   First Name      536885 non-null  object \n",
      " 2   Last Name       536885 non-null  object \n",
      " 3   Address         409097 non-null  object \n",
      " 4   City            409097 non-null  object \n",
      " 5   State_Abbr      409097 non-null  object \n",
      " 6   Zip             409097 non-null  float64\n",
      " 7   Start_Date      536885 non-null  object \n",
      " 8   Date            536885 non-null  object \n",
      " 9   Transaction_ID  536885 non-null  int64  \n",
      " 10  Department      536885 non-null  object \n",
      " 11  Category        536885 non-null  object \n",
      " 12  SKU             536885 non-null  object \n",
      " 13  Price           536885 non-null  float64\n",
      " 14  Discount        22705 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 61.4+ MB\n"
     ]
    }
   ],
   "source": [
    "Customer_Transactions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751c82d",
   "metadata": {},
   "source": [
    "### <a id=\"5\"></a>Save loaded tables\n",
    "- File directory\n",
    "- Merged Customers\n",
    "- Merged Transactions\n",
    "\n",
    "The tables are loaded and saved separately. It can be used the analysis to get a better understanding of the customers' transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c1b35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to save the loaded tables\n",
    "output_path = mainDir + \"Loaded_Data/\"\n",
    "os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1498f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filepaths for easier access\n",
    "payload_files.to_csv(output_path + \"payload_files_directory.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2eccb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged Customers table\n",
    "Customers.to_csv(output_path + \"Customers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cc03045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged Transactions table\n",
    "Transactions.to_csv(output_path + \"Transactions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d93e96d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save joined Customer_Transactions table for analysis\n",
    "Customer_Transactions.to_excel(output_path + \"Customer_Transactions.xlsx\", index=False, sheet_name=\"Customer_Transactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227e0fbb",
   "metadata": {},
   "source": [
    "Saving a Log file of this run for future reference or checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cecbe81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "functions.save_notebook()\n",
    "current_file = 'Dataload_AP.ipynb'\n",
    "output_file = 'Dataload_AP.html'\n",
    "functions.output_HTML(current_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed931c",
   "metadata": {},
   "source": [
    "### Dataload Compeleted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
